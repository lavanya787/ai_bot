device: "cpu"         # or "cuda" if GPU available
d_model: 128
n_layers: 4
num_heads: 4
ff_dim: 256
max_len: 64
vocab_path: "tokenizer/vocab.json"
checkpoint_path: "saved_models/transformer_model.pt"
